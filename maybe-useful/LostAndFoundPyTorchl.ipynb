{"cells":[{"cell_type":"markdown","metadata":{"id":"8SInWHQsQwwZ"},"source":["# This notebook was used to:\n","- Downlaod LostAndFound dataset using TF.\n","- Convert to PyTorch-compatible datatypes\n","- Comress and save -> Export to Google Drive."]},{"cell_type":"markdown","source":["### Imports"],"metadata":{"id":"-6gLVcaE4rhz"}},{"cell_type":"code","source":["import os\n","import torch\n","import tarfile\n","import tensorflow_datasets as tfds\n","from tqdm import tqdm"],"metadata":{"id":"QHGUuFyf4577","executionInfo":{"status":"ok","timestamp":1750013736071,"user_tz":-120,"elapsed":3,"user":{"displayName":"Jose Edgar Hernandez","userId":"01757118399331940284"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Utils"],"metadata":{"id":"j_hZYMKz40Qh"}},{"cell_type":"code","source":["def save_tf_dataset_as_pt(tf_dataset, output_dir, binary_mask=True):\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    for i, item in enumerate(tqdm(tf_dataset, desc=f\"Saving to {output_dir}\")):\n","        # Extract raw tensors from TF\n","        image = item['image_left'].numpy()        # shape: (1024, 2048, 3)\n","        mask = item['segmentation_label'].numpy() # shape: (1024, 2048, 1)\n","\n","        # Remove last channel from mask if needed\n","        if mask.shape[-1] == 1:\n","            mask = mask[..., 0]  # shape: (1024, 2048)\n","\n","        image_tensor = torch.from_numpy(image)  # uint8 [H, W, 3]\n","        mask_tensor = torch.from_numpy(mask)    # uint8 or int\n","\n","        # Save image and mask together\n","        save_path = os.path.join(output_dir, f\"{i:05d}.pt\")\n","        torch.save({\n","            'image': image_tensor,\n","            'mask': mask_tensor\n","        }, save_path)\n","\n","    print(f\"Saved {i+1} samples to {output_dir}\")\n","\n","\n","def tar_folder(folder_path, tar_name):\n","    with tarfile.open(tar_name, \"w:gz\") as tar:\n","        tar.add(folder_path, arcname=os.path.basename(folder_path))\n","    print(f\"Created tar.gz: {tar_name}\")"],"metadata":{"id":"pJ195Oqf46Tw","executionInfo":{"status":"ok","timestamp":1750012947291,"user_tz":-120,"elapsed":8,"user":{"displayName":"Jose Edgar Hernandez","userId":"01757118399331940284"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["### Load and convert data"],"metadata":{"id":"i0K0L8OQ5nd8"}},{"cell_type":"code","source":["dataset, info = tfds.load(\"lost_and_found\", with_info=True, as_supervised=False)"],"metadata":{"id":"lgoJhCKI5xTv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save to disk\n","save_tf_dataset_as_pt(dataset['train'], output_dir=\"./laf_train\")\n","save_tf_dataset_as_pt(dataset['test'], output_dir=\"./laf_test\")\n","\n","# Compress\n","tar_folder('./laf_test', 'laf_test.tar.gz')\n","tar_folder('./laf_train', 'laf_train.tar.gz')"],"metadata":{"id":"nvReZuzm50Q5","executionInfo":{"status":"ok","timestamp":1750013762036,"user_tz":-120,"elapsed":3,"user":{"displayName":"Jose Edgar Hernandez","userId":"01757118399331940284"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","!cp laf_train.tar.gz /content/drive/MyDrive/\n","!cp laf_test.tar.gz /content/drive/MyDrive/"],"metadata":{"id":"584nNHrd59b-"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[{"file_id":"1m2vCqUgv2wZKE1jrJ5XoTRZhPYXNkIoh","timestamp":1750012455984}],"collapsed_sections":["-6gLVcaE4rhz","j_hZYMKz40Qh"]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"}},"nbformat":4,"nbformat_minor":0}